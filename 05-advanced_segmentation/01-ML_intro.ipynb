{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d474ea6d-28c3-4269-8e6d-466df27ba0db",
   "metadata": {},
   "source": [
    "# ML introduction\n",
    "\n",
    "Until now we have seen classical image processing and in particular segmentation methods. Over the last decade new methods based on Machine Learning (ML) and in particular Deep Learning have emerged. Those methods are powerful but usually more difficult to use both on a hardware and software level.\n",
    "\n",
    "These methods can be used for denoising data, segmenting cells, tracking objects etc. What they have in common is their \"data-centricity\". While in classical methods, one investigates the properties available in the data in order to define an algorithm that solves a specific problem (e.g. filtering an image with a gaussian of a *specific size* matching that of the objects of interest in order to detect it), ML methods essentially learn interesting properties of the data *by themselves*. For this one needs usually large amounts of *annotated data*, i.e. already analyzed data that the ML algorithm can use to *learn* interesting features.\n",
    "\n",
    "In this chapter, we will mainly use ML methods for segmentation. In this particular area, ML methods that one could call \"smart\" have emerged. Instead of just consider images and their corresponding labels, these methods contain specific constraints on how the objects to be detected should look like. For example the StarDist method assumes that objects are star-convex (any point on the border can be reached from a point inside the shape), which is reasonable e.g. for nuclei segmentation. These limitations drastically reduce the space of possible objects to be detected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d1d703-1a5f-416e-aee2-e26b2c67745b",
   "metadata": {},
   "source": [
    "## Some vocabulary and specificities\n",
    "\n",
    "When you want to use a Deep Learning method you are going to constantly hear certain terms and concepts. We quickly summarize some of them here.\n",
    "\n",
    "### GPU\n",
    "\n",
    "GPUs are Graphical Processing Units. They have been initially developed to deal with graphics rendering (they are heavily used in gaming consoles for example) which is very compute intensive, but are massively used these days for Deep Learning. Their strength is that they can do many operations in parallel, massively decreasing computing time in certain cases compared to standard CPUs. They are however much less versatile than CPUs, and therefore remain confined to specific applications.\n",
    "\n",
    "\n",
    "### Networks or models\n",
    "\n",
    "Deep Learning methods are built on top of so-called networks: series of successive mathematical operators (like filters) that take an input and output a specific results. For example a segmentation algorithm will take an intensity image as input, pass it through a complex network of filters, and in the end output a labeled image. Sometimes networks are also called *models*.\n",
    "\n",
    "\n",
    "### Training\n",
    "\n",
    "As mentioned above, ML algorithms learn from data. During this learning process called *training*, all annotated examples (e.g. pairs of images and segmentations) go through the network which is slowly adapting to return the best possible output (segmentation). Once a satisfying result is reached, one says that the *networks is trained* or *pre-trained*.\n",
    "\n",
    "### Inference\n",
    "\n",
    "Once a model has been trained with annotated data (for which we already know the answer), we can use them on *new* data. Passing an image through a trained network is called the *inference step*.\n",
    "\n",
    "### Fine-tuninig\n",
    "\n",
    "In most cases, ML methods require to be trained on data that have very close features to to those that should be processed in the end. This requires re-training of algorithms even for relatively small experimental deviations.\n",
    "\n",
    "Instead of completely retraining an algorithm, one can also just fine-tune it. If the data to be processed are not too far from those used for training, one can start from the trained algorithm and just nudge it into the correct direction. This requires much less training data and is much faster.\n",
    "\n",
    "### Generalistic or versatile algotithm\n",
    "\n",
    "Another popular recent method, Cellpose, is by design much more generalistic. It is capable of detecting cells and nuclei in microscopy data but has been trained on a vast amount of very varied data, including fluorescence and electron microscopy, making it very versatile. The algorithm can naturally also be trained or fine-tuned for a much narrower task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a848fb4f-c62d-435a-b742-ca596edd9502",
   "metadata": {},
   "source": [
    "## ZerosCostDL4Mic\n",
    "\n",
    "The Zero Cost Deep Learning for Microscopy project aims to make the usage of advanced DL algorithm much easier than it usually is. It has collected a large series of methods and offers for each of them a notebook to follow step by step either to train, fine-tune or use an algorithm. These notebooks run entirely on Google Colab, an equivalent of Jupyter Notebooks that runs on Google infrastructure (for free) and which also offers free access to GPU computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f04c03a-73cf-4866-b05f-ca4dd0f3cc9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
